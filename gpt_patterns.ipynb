{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scorer import GPTHypernymySuiteModel, HFLMScorer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from hypernymysuite.evaluation import all_evaluations\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from leven import levenshtein\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res_table(res, return_mean=False):\n",
    "    metrics = []\n",
    "    metrics.append(res['siege_bless']['other']['ap_test_inv'])\n",
    "    metrics.append(res['siege_eval']['other']['ap_test_inv'])\n",
    "    metrics.append(res['siege_leds']['other']['ap_test_inv'])\n",
    "    metrics.append(res['siege_shwartz']['other']['ap_test_inv'])\n",
    "    metrics.append(res['siege_weeds']['other']['ap_test_inv'])\n",
    "\n",
    "    metrics.append(res['dir_dbless']['acc_test_inv'])\n",
    "    metrics.append(res['dir_wbless']['acc_test_inv'])\n",
    "    metrics.append(res['dir_bibless']['acc_test_inv'])\n",
    "\n",
    "    metrics.append(res['cor_hyperlex']['rho_test_inv'])\n",
    "    mean = np.mean(metrics)\n",
    "    metrics.append(mean)\n",
    "    metrics = [f'{val:.2f}'.replace('.', ',') for val in metrics]\n",
    "    if return_mean:\n",
    "        return ' '.join(metrics), mean\n",
    "    return ' '.join(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Envs/mtikhomi/lib/python3.6/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2-xl'\n",
    "device = 'cuda'\n",
    "scorer = HFLMScorer(model_name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "vocab['<OOV>'] = 1\n",
    "for file_name in os.listdir(eval_data_dir):\n",
    "    file_path = os.path.join(eval_data_dir, file_name)\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    for w in df['word1']:\n",
    "        vocab[w] = 1\n",
    "    for w in df['word2']:\n",
    "        vocab[w] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERNYMY PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    'gen': [\"<hyper> is more general than <hypo>\"],\n",
    "    'spec': [\"<hypo> is more specific than <hyper>\"],\n",
    "    'type': [\"<hypo> is a type of <hyper>\"],\n",
    "    'hyper1': [\"<hypo> which is a (example|class|kind|. . . ) of <hyper>\"],\n",
    "    'hyper2': [\"<hypo> which is a example of <hyper>\"],\n",
    "    'hyper3': [\"<hypo> which is a class of <hyper>\"],\n",
    "    'hyper4': [\"<hypo> which is a kind of <hyper>\"],\n",
    "    'hyper5': [\"<hypo> which is a type of <hyper>\"],\n",
    "    'hyper6': [\"<hypo> (and|or) (any|some) other <hyper>\"],\n",
    "    'hyper7': [\"<hypo> and any other <hyper>\"],\n",
    "    'hyper8': [\"<hypo> and some other <hyper>\"],\n",
    "    'hyper9': [\"<hypo> or any other <hyper>\"],\n",
    "    'hyper10': [\"<hypo> or some other <hyper>\"],\n",
    "    'hyper11': [\"<hypo> which is called <hyper>\"],\n",
    "    'hyper12': [\"<hypo> a special case of <hyper>\"],\n",
    "    'hyper13': [\"<hypo> is an <hyper> that\"],\n",
    "    'hyper14': [\"(Unlike|like) (most|all|any|other) <hyper>, <hypo>\"],\n",
    "    'hyper15': [\"unlike most <hyper>, <hypo>\"],\n",
    "    'hyper16': [\"unlike all <hyper>, <hypo>\"],\n",
    "    'hyper17': [\"unlike any <hyper>, <hypo>\"],\n",
    "    'hyper18': [\"unlike other <hyper>, <hypo>\"],\n",
    "    'hyper19': [\"like most <hyper>, <hypo>\"],\n",
    "    'hyper20': [\"like all <hyper>, <hypo>\"],\n",
    "    'hyper21': [\"like any <hyper>, <hypo>\"],\n",
    "    'hyper22': [\"like other <hyper>, <hypo>\"],\n",
    "    'hyper23': [\"<hyper> including <hypo>\"],\n",
    "    'hyper24': [\"such <hyper> as <hypo>\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<hypo> or some other <hyper>', 'such <hyper> as <hypo>']\n"
     ]
    }
   ],
   "source": [
    "patterns = PROMPTS['hyper10'] + PROMPTS['hyper24']\n",
    "print(patterns)\n",
    "hs_model = GPTHypernymySuiteModel(scorer, patterns, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:06<00:00,  7.61it/s]\n",
      "100%|██████████| 53/53 [00:05<00:00,  9.19it/s]\n",
      "100%|██████████| 53/53 [00:06<00:00,  7.79it/s]\n",
      "100%|██████████| 53/53 [00:05<00:00,  9.36it/s]\n",
      "100%|██████████| 53/53 [00:06<00:00,  7.65it/s]\n",
      "100%|██████████| 53/53 [00:05<00:00,  9.36it/s]\n",
      "100%|██████████| 42/42 [00:05<00:00,  7.49it/s]\n",
      "100%|██████████| 42/42 [00:04<00:00,  8.91it/s]\n",
      "100%|██████████| 42/42 [00:05<00:00,  7.38it/s]\n",
      "100%|██████████| 42/42 [00:04<00:00,  8.91it/s]\n",
      "100%|██████████| 68/68 [00:08<00:00,  7.90it/s]\n",
      "100%|██████████| 68/68 [00:07<00:00,  9.63it/s]\n",
      "100%|██████████| 452/452 [01:04<00:00,  7.06it/s]\n",
      "100%|██████████| 452/452 [00:54<00:00,  8.28it/s]\n",
      "100%|██████████| 87/87 [00:11<00:00,  7.26it/s]\n",
      "100%|██████████| 87/87 [00:09<00:00,  8.70it/s]\n",
      "100%|██████████| 421/421 [00:47<00:00,  8.79it/s]\n",
      "100%|██████████| 421/421 [00:40<00:00, 10.29it/s]\n",
      "100%|██████████| 53/53 [00:07<00:00,  7.51it/s]\n",
      "100%|██████████| 53/53 [00:05<00:00,  8.91it/s]\n",
      "100%|██████████| 1644/1644 [04:46<00:00,  5.73it/s]\n",
      "100%|██████████| 1644/1644 [04:27<00:00,  6.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0,53 0,37 0,86 0,47 0,89 0,96 0,75 0,71 0,62 0,68'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = all_evaluations(hs_model)\n",
    "print_res_table(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINED PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Envs/mtikhomi/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ft_model_name = 'cc.en.300.bin'\n",
    "ft = gensim.models.FastText.load_fasttext_format(ft_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1921/46973 [03:31<1:26:02,  8.73it/s]"
     ]
    }
   ],
   "source": [
    "w2cands = {}\n",
    "for w in tqdm(vocab):\n",
    "    w2cands[w] = ft.wv.most_similar(w, topn=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing candidates 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2cands_f = {}\n",
    "for w in tqdm(w2cands):\n",
    "    w2cands_f[w] = [d for d in w2cands[w] if (d[1] not in w) and (w not in d[1]) and (levenshtein(w, d[1]) > (len(w) / 2))][:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing candidates 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in tqdm(w2cands_f):\n",
    "    w2cands_f[w] = [d for d in w2cands_f[w] if '.' not in d[1] and d[1][0] != '-' and d[1][-1] != '-'][:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing candidates 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in tqdm(w2cands_f):\n",
    "    w2cands_f[w] = [d for d in w2cands_f[w] if len(wn.synsets(d[1]) > 0)][:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### candidates cohypo ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = ['<hypo> or <hyper>']\n",
    "cohypo_model = GPTHypernymySuiteModel(scorer, patterns, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2cands_f = {}\n",
    "for w in w2cands_f:\n",
    "    l = len(w2cands_f[w])\n",
    "    scores = cohypo_model.predict_many([w for i in range(l)], [d[1] for d in w2cands_f[w]])\n",
    "    w2cands_f[w] = sorted([[scores[i], w2cands_f[w][i][1]] for i in range(l)], key=lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 3\n",
    "word2cohypos = {w: [d[1] for d in w2cands_f[w][:topk]] for w in w2cands_f}\n",
    "word2cohypos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtikhomi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
